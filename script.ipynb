{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d639a2-9e2b-4290-b082-27af06bc9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "import progressbar\n",
    "import os\n",
    "import numpy as np\n",
    "import click\n",
    "\n",
    "from loguru import logger\n",
    "from urllib.error import URLError\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588fcfb0-2533-42e4-9eaa-2736e17e418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_sisyphus = 'https://rdb.altlinux.org/api/export/branch_binary_packages/sisyphus' #sisyphus\n",
    "URL_sp10 = 'https://rdb.altlinux.org/api/export/branch_binary_packages/p10' #p10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94901690-f074-452a-ba13-6a232b7c433e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.add('debug.log', format=\"{time} {level} {message}\", level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a117f39-1866-4454-a731-da90a1228edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(block_num, block_size, total_size):\n",
    "    \n",
    "    '''Function to generate progress bar'''\n",
    "    \n",
    "    global pbar\n",
    "    if pbar is None:\n",
    "        logger.debug('Creating progress bar')\n",
    "        pbar = progressbar.ProgressBar(maxval=total_size, widgets=[\n",
    "    'Downloading:', \n",
    "    progressbar.Bar(left='[', marker='=', right=']'), # Progress\n",
    "    progressbar.Percentage(), # Percentage\n",
    "    ' Bytes: ',\n",
    "    progressbar.SimpleProgress(), # Number of bytes\n",
    "    ' Network: ',\n",
    "    progressbar.FileTransferSpeed(), # Transfer speed-o-meeter\n",
    "    ])\n",
    "        pbar.start() # Lauching progress bar\n",
    "\n",
    "    downloaded = block_num * block_size\n",
    "    if downloaded < total_size:\n",
    "        pbar.update(downloaded)\n",
    "    else:\n",
    "        pbar.finish()\n",
    "        pbar = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30f84774-dc07-400b-80cf-e38efc395641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @click.command()\n",
    "# @click.option('--force', '-f', default=False, show_default=True, help=\"Use after reading README\")\n",
    "def download_data(flag=False):\n",
    "    \n",
    "    \"\"\"Entry point function and file upload\n",
    "    and compare lists of versions of packages\n",
    "     -force\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        logger.info('Access successful')\n",
    "        logger.info('Starting to download firts package from %s', URL_sisyphus)\n",
    "        tmp_sis = urllib.request.urlretrieve(URL_sisyphus, 'chache_sis.tmp', show_progress) #Downloading the firts part of data\n",
    "        logger.info('Download from %s complete', URL_sisyphus)\n",
    "        df_sis =  preparing_data(tmp_sis)                              # Making dataframes\n",
    "        \n",
    "        \n",
    "        logger.info('Starting to download second package from %s', URL_sp10)\n",
    "        tmp_p10 = urllib.request.urlretrieve(URL_sp10, 'chache_p10.tmp', show_progress) #Downloading the second part of data\n",
    "        logger.info('Download from %s complete', URL_sp10)\n",
    "        df_p10 = preparing_data(tmp_p10)     # Making dataframes\n",
    "        \n",
    "        if flag:\n",
    "            data_comparator(df_sis, df_p10, flag)\n",
    "        elif not flag:\n",
    "            data_comparator(df_sis, df_p10)\n",
    "            \n",
    "    except HTTPError as exception:\n",
    "        raise exception\n",
    "    except URLError as exception:\n",
    "        if isinstance(exception.reason, exception.timeout):\n",
    "            logger.error('Timeout Error: Data of %s not retrieved because %s\\nURL: %s', name, error, url)\n",
    "        else:\n",
    "            logger.error('URL Error: Data of %s not retrieved because %s\\nURL: %s', name, error, url)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3943b956-c7b5-40e1-8ea3-3a32d43b644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_dataframe(json_object: dict, path):\n",
    "    \n",
    "    \"\"\"Function to convert json to Dataframe for processing\"\"\"\n",
    "    \n",
    "    logger.info('Making Dataframe of %s', path)\n",
    "    \n",
    "    df0 = pd.DataFrame(json_object['packages'])  # Making DataFrame from JSON used only 'packages' because there is all data which we need\n",
    "    df = df0.sort_values(by=['name', 'version']) # Sorting data\n",
    "    df = df.drop_duplicates(keep='last')         # Deleting duplicated rows\n",
    "    df = df.dropna(subset=['name', 'version', 'release']) # Deleting NaN rows by subset columns\n",
    "    df = df.reset_index(drop=True)               # Resetting indexies in table\n",
    "    \n",
    "    name = path.split('.')[0]                    # Name of future .csv table with got data\n",
    "    \n",
    "    df.to_csv(f'{name}.csv')                     # Saving of csv table with data for future\n",
    "    \n",
    "    #checking if file exist or not\n",
    "    if(os.path.isfile(path)):\n",
    "    \n",
    "        #os.remove() function to remove the file\n",
    "        os.remove(path)\n",
    "    \n",
    "        logger.info(\"Temporary file (%s) deleted successfully\", path)\n",
    "    else:\n",
    "        logger.error(\"Temporary file does not exist\")\n",
    "        \n",
    "    logger.info('Making DataFrame already finished')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c92444-6edb-4b66-af84-2cc9700ebe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_data(tmp: tuple) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    path = tmp[0] # Getter of path and name of future file\n",
    "    \n",
    "    logger.info('Converting byte-like string %s to JSON', path)\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        json_object = json.load(file) # Making str -> dict convertation\n",
    "        logger.info('JSON saved')\n",
    "    \n",
    "    return making_dataframe(json_object, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b005b44-4588-4ee2-a8db-f1919150456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_comparator(df_sis: pd.core.frame.DataFrame, df_p10: pd.core.frame.DataFrame, cross_analysis=False):\n",
    "    \n",
    "    \"\"\"Function for generating reports on branches in the DataFrame format\"\"\"\n",
    "    \n",
    "    dfs = pd.merge(df_sis, df_p10, how='inner')         # Find the intersection of tables\n",
    "    \n",
    "    #Add intersections as duplicates and delete them *crutch\n",
    "    df_sis = df_sis.append(dfs)                      \n",
    "    df_p10 = df_p10.append(dfs)\n",
    "    \n",
    "    df_sis = df_sis.drop_duplicates(keep=False)\n",
    "    df_p10 = df_p10.drop_duplicates(keep=False)\n",
    "    \n",
    "    # Reseting indexies\n",
    "    df_sis = df_sis.reset_index(drop=True)\n",
    "    df_p10 = df_p10.reset_index(drop=True)\n",
    "    \n",
    "    result_json_sis = df_sis.to_json(orient=\"columns\")\n",
    "    result_json_p10 = df_p10.to_json(orient=\"columns\")\n",
    "    \n",
    "    with open('result_json_sis.txt', 'w') as file:\n",
    "        file.write(result_json_sis)\n",
    "    with open('result_json_p10.txt', 'w') as file:\n",
    "        file.write(result_json_p10)\n",
    "    \n",
    "    \"\"\"Cross-analysis works O (n ^ 2), for some reason pandas stubbornly refuses to compare sets,\n",
    "        and I didn’t fasten the SKL because of time pressure, I’m sorry\n",
    "        This is a head-on solution and it is not optimal, there is a much easier way to solve this problem\"\"\"\n",
    "    \n",
    "    res = False\n",
    "    \n",
    "    if cross_analysis:\n",
    "        \n",
    "        df_sis_croped = df_sis.drop(columns=['epoch', 'release', 'disttag', 'buildtime', 'source'])\n",
    "        df_p10_croped = df_p10.drop(columns=['epoch', 'release', 'disttag', 'buildtime', 'source'])\n",
    "        \n",
    "        df_sis_croped['newer'] = True\n",
    "        \n",
    "        for i, x in df_sis_croped.iterrows():\n",
    "            for j, y in df_sis_croped.iterrows():\n",
    "                if x[0] == y[0] and x[1] == y[1] and x[2] < y[2]:\n",
    "                    df_sis_croped.drop(index=[i], inplace = True)\n",
    "        res = df_sis_croped.to_json(orient=\"columns\")\n",
    "    \n",
    "    return result_json_sis, result_json_p10, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ef6dbe5-e079-4f56-a032-d190c842faac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 08:47:22.502 | INFO     | __main__:download_data:12 - Access successful\n",
      "2022-10-17 08:47:22.503 | INFO     | __main__:download_data:13 - Starting to download firts package from %s\n",
      "2022-10-17 08:47:29.371 | DEBUG    | __main__:show_progress:7 - Creating progress bar\n",
      "Downloading:[============]100% Bytes: 33465007 of 33465007 Network: 336.57 kB/s\n",
      "2022-10-17 08:49:08.817 | INFO     | __main__:download_data:15 - Download from %s complete\n",
      "2022-10-17 08:49:08.817 | INFO     | __main__:preparing_data:5 - Converting byte-like string %s to JSON\n",
      "2022-10-17 08:49:09.089 | INFO     | __main__:preparing_data:9 - JSON saved\n",
      "2022-10-17 08:49:09.089 | INFO     | __main__:making_dataframe:5 - Making Dataframe of %s\n",
      "2022-10-17 08:49:10.645 | INFO     | __main__:making_dataframe:23 - Temporary file (%s) deleted successfully\n",
      "2022-10-17 08:49:10.645 | INFO     | __main__:making_dataframe:27 - Making DataFrame already finished\n",
      "2022-10-17 08:49:10.689 | INFO     | __main__:download_data:19 - Starting to download second package from %s\n",
      "2022-10-17 08:49:17.259 | DEBUG    | __main__:show_progress:7 - Creating progress bar\n",
      "Downloading:[============]100% Bytes: 32948026 of 32948026 Network: 258.73 kB/s\n",
      "2022-10-17 08:51:24.606 | INFO     | __main__:download_data:21 - Download from %s complete\n",
      "2022-10-17 08:51:24.607 | INFO     | __main__:preparing_data:5 - Converting byte-like string %s to JSON\n",
      "2022-10-17 08:51:24.902 | INFO     | __main__:preparing_data:9 - JSON saved\n",
      "2022-10-17 08:51:24.903 | INFO     | __main__:making_dataframe:5 - Making Dataframe of %s\n",
      "2022-10-17 08:51:26.520 | INFO     | __main__:making_dataframe:23 - Temporary file (%s) deleted successfully\n",
      "2022-10-17 08:51:26.521 | INFO     | __main__:making_dataframe:27 - Making DataFrame already finished\n",
      "C:\\Users\\Namco\\AppData\\Local\\Temp\\ipykernel_11320\\2420643594.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_sis = df_sis.append(dfs)\n",
      "C:\\Users\\Namco\\AppData\\Local\\Temp\\ipykernel_11320\\2420643594.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_p10 = df_p10.append(dfs)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    pbar = None # Making entitiy for future progress bar\n",
    "    download_data() # Entry-point of script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
